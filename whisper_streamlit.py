# whisper_streamlit.py

import streamlit as st
import sounddevice as sd
import numpy as np
import threading
import queue
import time
import tempfile
import os
from faster_whisper import WhisperModel
import datetime
import wave

# === SETUP ===

st.set_page_config(page_title="Whisper è­°äº‹éŒ²", layout="centered")

st.title("ğŸ™ï¸ Whisper ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è­°äº‹éŒ²")
st.caption("éŒ²éŸ³ â†’ è‡ªå‹•æ–‡å­—èµ·ã“ã— â†’ ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãã§è¡¨ç¤º")

# === PARAMETERS ===

SAMPLE_RATE = 16000
CHANNELS = 1
BLOCKSIZE = 1024

# === GLOBALS ===

audio_q = queue.Queue()
recording = False
transcriptions = []
audio_buffer = []

# === INIT WHISPER ===

@st.cache_resource
def load_model():
    return WhisperModel("base", compute_type="auto")

model = load_model()

# === AUDIO HANDLING ===

def audio_callback(indata, frames, time_info, status):
    if recording:
        audio_q.put(indata.copy())

def record_audio():
    global recording
    with sd.InputStream(samplerate=SAMPLE_RATE, channels=CHANNELS, callback=audio_callback, blocksize=BLOCKSIZE):
        while recording:
            time.sleep(0.1)

def save_wav(frames, path):
    with wave.open(path, 'wb') as wf:
        wf.setnchannels(CHANNELS)
        wf.setsampwidth(2)
        wf.setframerate(SAMPLE_RATE)
        wf.writeframes(b''.join(frames))

def transcribe_audio(frames):
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as f:
        save_wav(frames, f.name)
        segments, _ = model.transcribe(f.name)
        results = []
        for segment in segments:
            ts = str(datetime.timedelta(seconds=int(segment.start)))
            results.append(f"[{ts}] {segment.text}")
        os.remove(f.name)
        return results

# === STREAMLIT UI ===

if "recording_state" not in st.session_state:
    st.session_state.recording_state = False

col1, col2 = st.columns(2)

if col1.button("âºï¸ éŒ²éŸ³é–‹å§‹", disabled=st.session_state.recording_state):
    st.session_state.recording_state = True
    recording = True
    audio_buffer.clear()
    thread = threading.Thread(target=record_audio)
    thread.start()
    st.success("éŒ²éŸ³ä¸­...")

if col2.button("â¹ï¸ åœæ­¢", disabled=not st.session_state.recording_state):
    st.session_state.recording_state = False
    recording = False
    st.warning("éŒ²éŸ³åœæ­¢ã—ã¾ã—ãŸã€‚éŸ³å£°å‡¦ç†ä¸­...")

    # Collect frames
    all_frames = []
    while not audio_q.empty():
        data = audio_q.get()
        all_frames.append(data.tobytes())

    transcription = transcribe_audio(all_frames)
    transcriptions.extend(transcription)
    st.success("æ–‡å­—èµ·ã“ã—å®Œäº†ï¼")

# === TRANSCRIPT DISPLAY ===

st.subheader("ğŸ“ è­°äº‹éŒ²")
if transcriptions:
    for line in transcriptions:
        st.markdown(f"- {line}")
else:
    st.info("ã¾ã è­°äº‹éŒ²ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
