# whisper_streamlit.py

import streamlit as st
import sounddevice as sd
import numpy as np
import threading
import queue
import time
import tempfile
import os
import wave
import datetime
from faster_whisper import WhisperModel

# === SETUP ===

st.set_page_config(page_title="Whisper è­°äº‹éŒ²", layout="centered")
st.title("ğŸ™ï¸ Whisper ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è­°äº‹éŒ²")
st.caption("éŒ²éŸ³ â†’ è‡ªå‹•æ–‡å­—èµ·ã“ã— â†’ ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãã§è¡¨ç¤º")

# === PARAMETERS ===

SAMPLE_RATE = 16000
CHANNELS = 1
BLOCKSIZE = 1024

# === GLOBALS ===

audio_q = queue.Queue()
recording_flag = {"value": False}  # â† ã‚¹ãƒ¬ãƒƒãƒ‰é–“ã§å…±æœ‰å¯èƒ½ãªãƒ•ãƒ©ã‚°

# === SESSION STATE INIT ===

if "recording_state" not in st.session_state:
    st.session_state.recording_state = False

if "transcriptions" not in st.session_state:
    st.session_state.transcriptions = []

# === WHISPER MODEL LOAD ===

@st.cache_resource
def load_model():
    return WhisperModel("base", compute_type="auto")

model = load_model()

# === AUDIO HANDLING ===

def audio_callback(indata, frames, time_info, status):
    if recording_flag["value"]:
        audio_q.put(indata.copy())

def record_audio():
    with sd.InputStream(samplerate=SAMPLE_RATE, channels=CHANNELS, callback=audio_callback, blocksize=BLOCKSIZE):
        while recording_flag["value"]:
            time.sleep(0.1)

def save_wav(frames, path):
    with wave.open(path, 'wb') as wf:
        wf.setnchannels(CHANNELS)
        wf.setsampwidth(2)
        wf.setframerate(SAMPLE_RATE)
        wf.writeframes(b''.join(frames))

def transcribe_audio(frames):
    fd, path = tempfile.mkstemp(suffix=".wav")
    os.close(fd)

    try:
        save_wav(frames, path)
        segments, _ = model.transcribe(path)
        results = []
        for segment in segments:
            ts = str(datetime.timedelta(seconds=int(segment.start)))
            results.append(f"[{ts}] {segment.text}")
        return results
    finally:
        try:
            os.remove(path)
        except Exception as e:
            print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å¤±æ•—: {e}")

# === UI CONTROLS ===

col1, col2 = st.columns(2)

if col1.button("âºï¸ éŒ²éŸ³é–‹å§‹", disabled=st.session_state.recording_state):
    st.session_state.recording_state = True
    recording_flag["value"] = True
    thread = threading.Thread(target=record_audio)
    thread.start()
    st.success("éŒ²éŸ³ä¸­...")

if col2.button("â¹ï¸ åœæ­¢", disabled=not st.session_state.recording_state):
    st.session_state.recording_state = False
    recording_flag["value"] = False
    st.warning("éŒ²éŸ³åœæ­¢ã—ã¾ã—ãŸã€‚éŸ³å£°å‡¦ç†ä¸­...")

    # éŸ³å£°ãƒ‡ãƒ¼ã‚¿åé›†
    all_frames = []
    while not audio_q.empty():
        data = audio_q.get()
        all_frames.append(data.tobytes())

    if all_frames:
        transcription = transcribe_audio(all_frames)
        st.session_state.transcriptions.extend(transcription)
        st.success("æ–‡å­—èµ·ã“ã—å®Œäº†ï¼")
    else:
        st.error("âš ï¸ éŸ³å£°ãŒéŒ²éŸ³ã•ã‚Œã¦ã„ã¾ã›ã‚“ã§ã—ãŸã€‚")

# === TRANSCRIPTION DISPLAY ===

st.subheader("ğŸ“ è­°äº‹éŒ²")
if st.session_state.transcriptions:
    for line in st.session_state.transcriptions:
        st.markdown(f"- {line}")
else:
    st.info("ã¾ã è­°äº‹éŒ²ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
